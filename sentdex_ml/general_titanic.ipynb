{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 2ms/step - loss: 0.6738 - accuracy: 0.6124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e19c6c45e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np # for math and arrays\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')\n",
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = tf.keras.layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = tf.keras.layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = tf.keras.layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)\n",
    "\n",
    "preprocessed_inputs_cat = tf.keras.layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}\n",
    "\n",
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)\n",
    "\n",
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(64),\n",
    "  tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = titanic_preprocessing(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.optimizers.Adam(),metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)\n",
    "\n",
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model spec combinations: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [14:46<00:00, 30.58s/it]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np # for math and arrays\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')\n",
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = tf.keras.layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = tf.keras.layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = tf.keras.layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)\n",
    "\n",
    "preprocessed_inputs_cat = tf.keras.layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}\n",
    "\n",
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)\n",
    "\n",
    "def return_compiled_model(how_many_dense_layers:int, layer_size:int,preprocessing_head, inputs) ->tf.keras.models.Sequential:\n",
    "    body = tf.keras.models.Sequential()\n",
    "    body.add(tf.keras.layers.Dense(64))\n",
    "    for i in range(how_many_dense_layers):\n",
    "        body.add(tf.keras.layers.Dense(layer_size))\n",
    "    body.add(tf.keras.layers.Dense(1))  \n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "            loss='BinaryCrossentropy',#'categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_short_name(how_many_dense_layers:int, layer_size:int) ->str:\n",
    "    return str(how_many_dense_layers)+'layers_'+str(layer_size)+'nodes_'\n",
    "\n",
    "all_model_specs = [{\"layers\": 0 ,\"nodes\": 0 }]\n",
    "layers = [1,2,3,4]\n",
    "nodes = [16,32,64,128,256,256*2,256*4]\n",
    "for layer in layers:\n",
    "    for node in nodes:\n",
    "        all_model_specs.append({\"layers\": layer ,\"nodes\": node })\n",
    "print(\"model spec combinations:\",len(all_model_specs))\n",
    "\n",
    "for model_spec in tqdm(all_model_specs):\n",
    "    log_name = create_model_short_name(model_spec['layers'],model_spec['nodes'])\n",
    "    log_dir = \"logs_titanic03_/fit/\" + log_name + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    model = return_compiled_model(model_spec['layers'],model_spec['nodes'],titanic_preprocessing, inputs)\n",
    "    with tf.device('/CPU:0'): # it can be with '/CPU:0'\n",
    "        history = model.fit(titanic_features_dict, titanic_labels, epochs=100, shuffle=True,  verbose=0\n",
    "        \n",
    "        , callbacks=[tensorboard_callback] ) #validation_data = (x_valid,y_valid),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7acfbe3706fe0fa8597ca3088a4f4c75dd0f746ca2f43477b557a1281a0f5f04"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venvsentdex': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
