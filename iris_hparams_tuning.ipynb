{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsHV-7cpVkyK"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [11:53<00:00, 79.27s/it]\n"
          ]
        }
      ],
      "source": [
        "#v: alles gleich aber iris daten\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np # for math and arrays\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "all_ds = pd.read_csv('iris_dataset.csv')\n",
        "# all_ds = all_ds.sample(frac=1) # This will randomly shuffle the rows to make sure the data is not sorted\n",
        "train_dataset, temp_test_dataset =  train_test_split(all_ds, test_size=0.3,random_state=42)\n",
        "test_dataset, valid_dataset =  train_test_split(temp_test_dataset, test_size=0.5,random_state=42)\n",
        "train_labels1 = train_dataset.pop('target')\n",
        "test_labels1 = test_dataset.pop('target')\n",
        "valid_labels1 = valid_dataset.pop('target')\n",
        "train_labels = pd.get_dummies(train_labels1, prefix='Label')\n",
        "valid_labels = pd.get_dummies(valid_labels1, prefix='Label')\n",
        "test_labels = pd.get_dummies(test_labels1, prefix='Label')\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "normed_train_data = pd.DataFrame(StandardScaler().fit_transform(train_dataset), columns=train_dataset.columns, index=train_dataset.index)\n",
        "normed_test_data = pd.DataFrame(StandardScaler().fit_transform(test_dataset), columns=test_dataset.columns, index=test_dataset.index)\n",
        "normed_valid_data = pd.DataFrame(StandardScaler().fit_transform(valid_dataset), columns=valid_dataset.columns, index=valid_dataset.index)\n",
        "x_train, y_train, x_valid, y_valid = normed_train_data, train_labels, normed_valid_data, valid_labels\n",
        "\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32,64,128,256, 256*2,256*4,256*8,256*8*2*2*2]))\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "HP_LR = hp.HParam('lr', hp.Discrete([0.01,0.001,0.0001,0.00001,]))\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "log_name = 'logs_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'/hparam_tuning'\n",
        "\n",
        "with tf.summary.create_file_writer(log_name).as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_OPTIMIZER, HP_LR],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )\n",
        "\n",
        "def helper_fct_return_optimizer_w_learn_rate(opt_name:str,lr:float):\n",
        "  if opt_name == \"sgd\":\n",
        "    return tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "  if opt_name == \"adam\":\n",
        "    return tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "  return \"error\"\n",
        "\n",
        "def train_test_model(hparams):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten( input_shape = (4,)),\n",
        "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS]),\n",
        "    # tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "    tf.keras.layers.Dense(3, activation='softmax'),\n",
        "  ])\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer=helper_fct_return_optimizer_w_learn_rate(hparams[HP_OPTIMIZER],hparams[HP_LR],),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "  model.fit(x_train, y_train,validation_data=(x_valid,y_valid),epochs=100, shuffle=True,  verbose=False) \n",
        "  _, accuracy = model.evaluate(x_valid, y_valid,verbose=False)\n",
        "  return accuracy\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "session_num = 0\n",
        "for num_units in tqdm(HP_NUM_UNITS.domain.values):\n",
        "  for lr in HP_LR.domain.values:\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {HP_NUM_UNITS: num_units, HP_OPTIMIZER: optimizer, HP_LR: lr}\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      run(log_name+ run_name, hparams)\n",
        "      session_num += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hyperparameter_tuning_with_hparams.ipynb",
      "toc_visible": true
    },
    "interpreter": {
      "hash": "3f4dddeb97c43720685b63285ae9cf6c7cf66ba0658824cdc3274f63bac11808"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('venvtb': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
